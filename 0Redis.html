<html>
  <head>
	  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <title>i5ting_ztree_toc:0Redis</title>
		<link href="toc/style/github-bf51422f4bb36427d391e4b75a1daa083c2d840e.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/style/github2-d731afd4f624c99a4b19ad69f3083cd6d02b81d5.css" media="all" rel="stylesheet" type="text/css"/>
		<link href="toc/css/zTreeStyle/zTreeStyle.css" media="all" rel="stylesheet" type="text/css"/>
	  <style>
		pre {
		    counter-reset: line-numbering;
		    border: solid 1px #d9d9d9;
		    border-radius: 0;
		    background: #fff;
		    padding: 0;
		    line-height: 23px;
		    margin-bottom: 30px;
		    white-space: pre;
		    overflow-x: auto;
		    word-break: inherit;
		    word-wrap: inherit;
		}

		pre a::before {
		  content: counter(line-numbering);
		  counter-increment: line-numbering;
		  padding-right: 1em; /* space after numbers */
		  width: 25px;
		  text-align: right;
		  opacity: 0.7;
		  display: inline-block;
		  color: #aaa;
		  background: #eee;
		  margin-right: 16px;
		  padding: 2px 10px;
		  font-size: 13px;
		  -webkit-touch-callout: none;
		  -webkit-user-select: none;
		  -khtml-user-select: none;
		  -moz-user-select: none;
		  -ms-user-select: none;
		  user-select: none;
		}

		pre a:first-of-type::before {
		  padding-top: 10px;
		}

		pre a:last-of-type::before {
		  padding-bottom: 10px;
		}

		pre a:only-of-type::before {
		  padding: 10px;
		}

		.highlight { background-color: #ffffcc } /* RIGHT */
		</style>
  </head>
  <body>
	  <div>
				<div style='width:25%;'>
						<ul id="tree" class="ztree" style='width:100%'>

						</ul>
				</div>
        <div id='readme' style='width:70%;margin-left:20%;'>
          	<article class='markdown-body'>
            	<h1 id="redis-">Redis入门</h1>
<h2 id="-">概述</h2>
<h3 id="redis-">Redis是什么？</h3>
<p>Redis（Remote Dictionary Server )，即远程字典服务，是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。</p>
<p>与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。</p>
<h3 id="redis-">Redis能该干什么？</h3>
<ol>
<li>内存存储、持久化，内存是断电即失的，所以需要持久化（RDB、AOF）</li>
<li>高效率、用于高速缓冲</li>
<li>发布订阅系统</li>
<li>地图信息分析</li>
<li>计时器、计数器(eg：浏览量)</li>
</ol>
<h3 id="-">核心特性</h3>
<ul>
<li>多样的数据类型</li>
<li>持久化</li>
<li>集群</li>
<li>事务</li>
</ul>
<h3 id="-">基础知识</h3>
<p>Redis是一个字典结构的存储服务器，一个Redis实例提供了多个用来存储数据的字典，客户端可以指定将这数据存储在哪个字典中，这与在一个关系型数据库实例（以MySQL为例）中可以创建多个数据库类似，可以将其中的每个字典都理解成一个独立的数据库。</p>
<p>16个数据库分别为：DB 0~DB 15，默认使用DB 0 ，可以使用<code>select n</code>切换到DB n，<code>dbsize</code>可以查看当前数据库的大小，与key数量相关。</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; config get databases # 命令行查看数据库数量databases
1) &quot;databases&quot;
2) &quot;16&quot;

127.0.0.1:6379&gt; select 8 # 切换数据库 DB 8
OK
127.0.0.1:6379[8]&gt; dbsize # 查看数据库大小
(integer) 0

# 不同数据库之间 数据是不能互通的，并且dbsize 是根据库中key的个数。
127.0.0.1:6379&gt; set name sakura 
OK
127.0.0.1:6379&gt; SELECT 8
OK
127.0.0.1:6379[8]&gt; get name # db8中并不能获取db0中的键值对。
(nil)
127.0.0.1:6379[8]&gt; DBSIZE
(integer) 0
127.0.0.1:6379[8]&gt; SELECT 0
OK
127.0.0.1:6379&gt; keys *
1) &quot;counter:__rand_int__&quot;
2) &quot;mylist&quot;
3) &quot;name&quot;
4) &quot;key:__rand_int__&quot;
5) &quot;myset:__rand_int__&quot;
127.0.0.1:6379&gt; DBSIZE # size和key个数相关
(integer) 5
</code></pre>
<p><code>keys *</code> ：查看当前数据库中所有的key。</p>
<p><code>flushdb</code>：清空当前数据库中的键值对。</p>
<p><code>flushall</code>：清空所有数据库的键值对。</p>
<div class="note warining"><p>keys *这个命令需要慎重使用，如果数据库中的键过多可能会造成卡顿，生产环境中应该使用dbsize</p></div>



<h2 id="-">保存中文</h2>
<p>redis-cli --raw</p>
<h2 id="-">五大数据类型</h2>
<p> Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持<a href="https://www.redis.net.cn/tutorial/3508.html">字符串</a>、<a href="https://www.redis.net.cn/tutorial/3509.html">哈希表</a>、<a href="https://www.redis.net.cn/tutorial/3510.html">列表</a>、<a href="https://www.redis.net.cn/tutorial/3511.html">集合</a>、<a href="https://www.redis.net.cn/tutorial/3512.html">有序集合</a>，<a href="https://www.redis.net.cn/tutorial/3508.html">位图</a>，<a href="https://www.redis.net.cn/tutorial/3513.html">hyperloglogs</a>等数据类型。内置复制、<a href="https://www.redis.net.cn/tutorial/3516.html">Lua脚本</a>、LRU收回、<a href="https://www.redis.net.cn/tutorial/3515.html">事务</a>以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动<a href="https://www.redis.net.cn/tutorial/3524.html">分区</a>。</p>
<h3 id="redis-key">Redis-key</h3>
<p>在redis中无论什么数据类型，在数据库中都是以key-value形式保存，通过进行对Redis-key的操作，来完成对数据库中数据的操作。</p>
<p>下面学习的命令：</p>
<ul>
<li><code>exists key</code>：判断键是否存在</li>
<li><code>del key</code>：删除键值对</li>
<li><code>move key db</code>：将键值对移动到指定数据库</li>
<li><code>expire key second</code>：设置键值对的过期时间</li>
<li><code>type key</code>：查看value的数据类型</li>
</ul>
<pre><code class="lang-bash">127.0.0.1:6379&gt; keys * # 查看当前数据库所有key
(empty list or set)
127.0.0.1:6379&gt; set name qinjiang # set key
OK
127.0.0.1:6379&gt; set age 20
OK
127.0.0.1:6379&gt; keys *
1) &quot;age&quot;
2) &quot;name&quot;
127.0.0.1:6379&gt; move age 1 # 将键值对移动到指定数据库
(integer) 1
127.0.0.1:6379&gt; EXISTS age # 判断键是否存在
(integer) 0 # 不存在
127.0.0.1:6379&gt; EXISTS name
(integer) 1 # 存在
127.0.0.1:6379&gt; SELECT 1
OK
127.0.0.1:6379[1]&gt; keys *
1) &quot;age&quot;
127.0.0.1:6379[1]&gt; del age # 删除键值对
(integer) 1 # 删除个数


127.0.0.1:6379&gt; set age 20
OK
127.0.0.1:6379&gt; EXPIRE age 15 # 设置键值对的过期时间

(integer) 1 # 设置成功 开始计数
127.0.0.1:6379&gt; ttl age # 查看key的过期剩余时间
(integer) 13
127.0.0.1:6379&gt; ttl age
(integer) 11
127.0.0.1:6379&gt; ttl age
(integer) 9
127.0.0.1:6379&gt; ttl age
(integer) -2 # -2 表示key过期，-1表示key未设置过期时间

127.0.0.1:6379&gt; get age # 过期的key 会被自动delete
(nil)
127.0.0.1:6379&gt; keys *
1) &quot;name&quot;

127.0.0.1:6379&gt; type name # 查看value的数据类型
string
</code></pre>
<p>关于<code>TTL</code>命令</p>
<p>Redis的key，通过TTL命令返回key的过期时间，一般来说有3种：</p>
<ol>
<li>当前key没有设置过期时间，所以会返回-1.</li>
<li>当前key有设置过期时间，而且key已经过期，所以会返回-2.</li>
<li>当前key有设置过期时间，且key还没有过期，故会返回key的正常剩余时间.</li>
</ol>
<p>关于重命名<code>RENAME</code>和<code>RENAMENX</code></p>
<ul>
<li><code>RENAME key newkey</code>修改 key 的名称</li>
<li><code>RENAMENX key newkey</code>仅当 newkey 不存在时，将 key 改名为 newkey 。</li>
</ul>
<p>更多命令学习：<a href="https://www.redis.net.cn/order/">Redis命令大全</a></p>
<p>实际上每种数据结构都有自己底层的内部编码实现，而且是多种实现，这样Redis会在合适的场景选择合适的内部编码</p>
<p>Redis这样设计有两个好处：</p>
<ul>
<li>可以改进内部编码，而对外的数据结构和命令没有影响，这样一旦开发出更优秀的内部编码，无需改动外部数据结构和命令</li>
<li>多种内部编码实现可以在不同场景下发挥各自的优势</li>
</ul>
<h3 id="string-">String(字符串)</h3>
<p>普通的set、get直接略过。</p>
<h4 id="-">应用场景</h4>
<p>1、缓存功能：String字符串是最常用的数据类型，不仅仅是redis，各个语言都是最基本类型，因此，利用redis作为缓存，配合其它数据库作为存储层，利用redis支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。</p>
<p>2、计数器：许多系统都会使用redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。</p>
<p>3、统计多单位的数量：eg，uid：gongming count：0 根据不同的uid更新count数量。</p>
<p>4、共享用户session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存cookie，这两种方式做有一定弊端，1）每次都重新登录效率低下 2）cookie保存在客户端，有安全隐患。这时可以利用redis将用户的session集中管理，在这种模式只需要保证redis的高可用，每次用户session的更新和获取都可以快速完成。大大提高效率。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>APPEND key value</td>
<td>向指定的key的value后追加字符串</td>
<td>127.0.0.1:6379&gt; set msg hello OK 127.0.0.1:6379&gt; append msg &quot; world&quot; (integer) 11 127.0.0.1:6379&gt; get msg “hello world”</td>
</tr>
<tr>
<td>DECR/INCR key</td>
<td>将指定key的value数值进行+1/-1(仅对于数字)</td>
<td>127.0.0.1:6379&gt; set age 20 OK 127.0.0.1:6379&gt; incr age (integer) 21 127.0.0.1:6379&gt; decr age (integer) 20</td>
</tr>
<tr>
<td>INCRBY/DECRBY key n</td>
<td>按指定的步长对数值进行加减</td>
<td>127.0.0.1:6379&gt; INCRBY age 5 (integer) 25 127.0.0.1:6379&gt; DECRBY age 10 (integer) 15</td>
</tr>
<tr>
<td>INCRBYFLOAT key n</td>
<td>为数值加上浮点型数值</td>
<td>127.0.0.1:6379&gt; INCRBYFLOAT age 5.2 “20.2”</td>
</tr>
<tr>
<td>STRLEN key</td>
<td>获取key保存值的字符串长度</td>
<td>127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; STRLEN msg (integer) 11</td>
</tr>
<tr>
<td>GETRANGE key start end</td>
<td>按起止位置获取字符串（闭区间，起止位置都取）</td>
<td>127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; GETRANGE msg 3 9 “lo worl”</td>
</tr>
<tr>
<td>SETRANGE key offset value</td>
<td>用指定的value 替换key中 offset开始的值</td>
<td>127.0.0.1:6379&gt; SETRANGE msg 2 hello (integer) 7 127.0.0.1:6379&gt; get msg “tehello”</td>
</tr>
<tr>
<td>GETSET key value</td>
<td>将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</td>
<td>127.0.0.1:6379&gt; GETSET msg test “hello world”</td>
</tr>
<tr>
<td>SETNX key value</td>
<td>仅当key不存在时进行set</td>
<td>127.0.0.1:6379&gt; SETNX msg test (integer) 0 127.0.0.1:6379&gt; SETNX name sakura (integer) 1</td>
</tr>
<tr>
<td>SETEX key seconds value</td>
<td>set 键值对并设置过期时间</td>
<td>127.0.0.1:6379&gt; setex name 10 root OK 127.0.0.1:6379&gt; get name (nil)</td>
</tr>
<tr>
<td>MSET key1 value1 [key2 value2..]</td>
<td>批量set键值对</td>
<td>127.0.0.1:6379&gt; MSET k1 v1 k2 v2 k3 v3 OK</td>
</tr>
<tr>
<td>MSETNX key1 value1 [key2 value2..]</td>
<td>批量设置键值对，仅当参数中所有的key都不存在时执行</td>
<td>127.0.0.1:6379&gt; MSETNX k1 v1 k4 v4 (integer) 0</td>
</tr>
<tr>
<td>MGET key1 [key2..]</td>
<td>批量获取多个key保存的值</td>
<td>127.0.0.1:6379&gt; MGET k1 k2 k3 1) “v1” 2) “v2” 3) “v3”</td>
</tr>
<tr>
<td>PSETEX key milliseconds value</td>
<td>和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，</td>
<td></td>
</tr>
<tr>
<td>getset key value</td>
<td>如果不存在值，则返回nil，如果存在值，获取原来的值，并设置新的值</td>
</tr>
</tbody>
</table>
<p>String类似的使用场景：value除了是字符串还可以是数字，用途举例：</p>
<ul>
<li>计数器</li>
<li>统计多单位的数量：uid:123666：follow 0</li>
<li>粉丝数</li>
<li>对象存储缓存</li>
</ul>
<h3 id="list-">List(列表)</h3>
<p>Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边），一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。</p>
<h4 id="-">应用场景</h4>
<p>1、消息队列：reids的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。</p>
<p>2、文章列表或者数据分页展示的应用。比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>LPUSH/RPUSH key value1[value2..]</code></td>
<td>从左边/右边向列表中PUSH值(一个或者多个)。</td>
</tr>
<tr>
<td><code>LRANGE key start end</code></td>
<td>获取list 起止元素（索引从左往右 递增）</td>
</tr>
<tr>
<td><code>LPUSHX/RPUSHX key value</code></td>
<td>向已存在的列名中push值（一个或者多个）</td>
</tr>
<tr>
<td>`LINSERT key BEFORE</td>
<td>AFTER pivot value`</td>
<td>在指定列表元素的前/后 插入value</td>
</tr>
<tr>
<td><code>LLEN key</code></td>
<td>查看列表长度</td>
</tr>
<tr>
<td><code>LINDEX key index</code></td>
<td>通过索引获取列表元素</td>
</tr>
<tr>
<td><code>LSET key index value</code></td>
<td>通过索引为元素设值</td>
</tr>
<tr>
<td><code>LPOP/RPOP key</code></td>
<td>从最左边/最右边移除值 并返回</td>
</tr>
<tr>
<td><code>RPOPLPUSH source destination</code></td>
<td>将列表的尾部(右)最后一个值弹出，并返回，然后加到另一个列表的头部</td>
</tr>
<tr>
<td><code>LTRIM key start end</code></td>
<td>通过下标截取指定范围内的列表</td>
</tr>
<tr>
<td><code>LREM key count value</code></td>
<td>List中是允许value重复的 <code>count &gt; 0</code>：从头部开始搜索 然后删除指定的value 至多删除count个 <code>count &lt; 0</code>：从尾部开始搜索… <code>count = 0</code>：删除列表中所有的指定value。</td>
</tr>
<tr>
<td><code>BLPOP/BRPOP key1[key2] timout</code></td>
<td>移出并获取列表的第一个/最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td>
</tr>
<tr>
<td><code>BRPOPLPUSH source destination timeout</code></td>
<td>和<code>RPOPLPUSH</code>功能相同，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">---------------------------LPUSH---RPUSH---LRANGE--------------------------------

127.0.0.1:6379&gt; LPUSH mylist k1 # LPUSH mylist=&gt;{1}
(integer) 1
127.0.0.1:6379&gt; LPUSH mylist k2 # LPUSH mylist=&gt;{2,1}
(integer) 2
127.0.0.1:6379&gt; RPUSH mylist k3 # RPUSH mylist=&gt;{2,1,3}
(integer) 3
127.0.0.1:6379&gt; get mylist # 普通的get是无法获取list值的
(error) WRONGTYPE Operation against a key holding the wrong kind of value
127.0.0.1:6379&gt; LRANGE mylist 0 4 # LRANGE 获取起止位置范围内的元素
1) &quot;k2&quot;
2) &quot;k1&quot;
3) &quot;k3&quot;
127.0.0.1:6379&gt; LRANGE mylist 0 2
1) &quot;k2&quot;
2) &quot;k1&quot;
3) &quot;k3&quot;
127.0.0.1:6379&gt; LRANGE mylist 0 1
1) &quot;k2&quot;
2) &quot;k1&quot;
127.0.0.1:6379&gt; LRANGE mylist 0 -1 # 获取全部元素
1) &quot;k2&quot;
2) &quot;k1&quot;
3) &quot;k3&quot;

---------------------------LPUSHX---RPUSHX-----------------------------------

127.0.0.1:6379&gt; LPUSHX list v1 # list不存在 LPUSHX失败
(integer) 0
127.0.0.1:6379&gt; LPUSHX list v1 v2  
(integer) 0
127.0.0.1:6379&gt; LPUSHX mylist k4 k5 # 向mylist中 左边 PUSH k4 k5
(integer) 5
127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k5&quot;
2) &quot;k4&quot;
3) &quot;k2&quot;
4) &quot;k1&quot;
5) &quot;k3&quot;

---------------------------LINSERT--LLEN--LINDEX--LSET----------------------------

127.0.0.1:6379&gt; LINSERT mylist after k2 ins_key1 # 在k2元素后 插入ins_key1
(integer) 6
127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k5&quot;
2) &quot;k4&quot;
3) &quot;k2&quot;
4) &quot;ins_key1&quot;
5) &quot;k1&quot;
6) &quot;k3&quot;
127.0.0.1:6379&gt; LLEN mylist # 查看mylist的长度
(integer) 6
127.0.0.1:6379&gt; LINDEX mylist 3 # 获取下标为3的元素
&quot;ins_key1&quot;
127.0.0.1:6379&gt; LINDEX mylist 0
&quot;k5&quot;
127.0.0.1:6379&gt; LSET mylist 3 k6 # 将下标3的元素 set值为k6
OK
127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k5&quot;
2) &quot;k4&quot;
3) &quot;k2&quot;
4) &quot;k6&quot;
5) &quot;k1&quot;
6) &quot;k3&quot;

---------------------------LPOP--RPOP--------------------------

127.0.0.1:6379&gt; LPOP mylist # 左侧(头部)弹出
&quot;k5&quot;
127.0.0.1:6379&gt; RPOP mylist # 右侧(尾部)弹出
&quot;k3&quot;

---------------------------RPOPLPUSH--------------------------

127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k4&quot;
2) &quot;k2&quot;
3) &quot;k6&quot;
4) &quot;k1&quot;
127.0.0.1:6379&gt; RPOPLPUSH mylist newlist # 将mylist的最后一个值(k1)弹出，加入到newlist的头部
&quot;k1&quot;
127.0.0.1:6379&gt; LRANGE newlist 0 -1
1) &quot;k1&quot;
127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k4&quot;
2) &quot;k2&quot;
3) &quot;k6&quot;

---------------------------LTRIM--------------------------

127.0.0.1:6379&gt; LTRIM mylist 0 1 # 截取mylist中的 0~1部分
OK
127.0.0.1:6379&gt; LRANGE mylist 0 -1
1) &quot;k4&quot;
2) &quot;k2&quot;

# 初始 mylist: k2,k2,k2,k2,k2,k2,k4,k2,k2,k2,k2
---------------------------LREM--------------------------

127.0.0.1:6379&gt; LREM mylist 3 k2 # 从头部开始搜索 至多删除3个 k2
(integer) 3
# 删除后：mylist: k2,k2,k2,k4,k2,k2,k2,k2

127.0.0.1:6379&gt; LREM mylist -2 k2 #从尾部开始搜索 至多删除2个 k2
(integer) 2
# 删除后：mylist: k2,k2,k2,k4,k2,k2


---------------------------BLPOP--BRPOP--------------------------

mylist: k2,k2,k2,k4,k2,k2
newlist: k1

127.0.0.1:6379&gt; BLPOP newlist mylist 30 # 从newlist中弹出第一个值，mylist作为候选
1) &quot;newlist&quot; # 弹出
2) &quot;k1&quot;
127.0.0.1:6379&gt; BLPOP newlist mylist 30
1) &quot;mylist&quot; # 由于newlist空了 从mylist中弹出
2) &quot;k2&quot;
127.0.0.1:6379&gt; BLPOP newlist 30
(30.10s) # 超时了

127.0.0.1:6379&gt; BLPOP newlist 30 # 我们连接另一个客户端向newlist中push了test, 阻塞被解决。
1) &quot;newlist&quot;
2) &quot;test&quot;
(12.54s)
</code></pre>
<p>小结：</p>
<ul>
<li>list实际上是一个链表，before Node after , left, right 都可以插入值</li>
<li>如果key不存在，则创建新的链表</li>
<li>如果key存在，新增内容</li>
<li>如果移除了所有值，空链表，也代表不存在</li>
<li>在两边插入或者改动值，效率最高！修改中间元素，效率相对较低</li>
</ul>
<p>应用：</p>
<ul>
<li>消息排队</li>
<li>消息队列（Lpush Rpop）</li>
<li>栈（Lpush Lpop）</li>
</ul>
<h3 id="set-">Set(集合)</h3>
<p>Redis的Set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)，集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p>
<h4 id="-">应用场景</h4>
<p>1、标签：比如我们博客网站常常使用到的兴趣标签，把一个个有着相同爱好，关注类似内容的用户利用一个标签把他们进行归并。</p>
<p>2、共同好友功能，共同喜好，或者可以引申到二度好友之类的扩展应用。</p>
<p>3、统计网站的独立IP。利用set集合当中元素不唯一性，可以快速实时统计访问网站的独立IP。</p>
<p>数据结构</p>
<p>set的底层结构相对复杂写，使用了intset和hashtable两种数据结构存储，intset可以理解为数组。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SADD key member1[member2..]</code></td>
<td>向集合中无序增加一个/多个成员</td>
</tr>
<tr>
<td><code>SCARD key</code></td>
<td>获取集合的成员数</td>
</tr>
<tr>
<td><code>SMEMBERS key</code></td>
<td>返回集合中所有的成员</td>
</tr>
<tr>
<td><code>SISMEMBER key member</code></td>
<td>查询member元素是否是集合的成员,结果是无序的</td>
</tr>
<tr>
<td><code>SRANDMEMBER key [count]</code></td>
<td>随机返回集合中count个成员，count缺省值为1</td>
</tr>
<tr>
<td><code>SPOP key [count]</code></td>
<td>随机移除并返回集合中count个成员，count缺省值为1</td>
</tr>
<tr>
<td><code>SMOVE source destination member</code></td>
<td>将source集合的成员member移动到destination集合</td>
</tr>
<tr>
<td><code>SREM key member1[member2..]</code></td>
<td>移除集合中一个/多个成员</td>
</tr>
<tr>
<td><code>SDIFF key1[key2..]</code></td>
<td>返回所有集合的差集 key1- key2 - …</td>
</tr>
<tr>
<td><code>SDIFFSTORE destination key1[key2..]</code></td>
<td>在SDIFF的基础上，将结果保存到集合中(覆盖)。不能保存到其他类型key噢！</td>
</tr>
<tr>
<td><code>SINTER key1 [key2..]</code></td>
<td>返回所有集合的交集</td>
</tr>
<tr>
<td><code>SINTERSTORE destination key1[key2..]</code></td>
<td>在SINTER的基础上，存储结果到集合中。覆盖</td>
</tr>
<tr>
<td><code>SUNION key1 [key2..]</code></td>
<td>返回所有集合的并集</td>
</tr>
<tr>
<td><code>SUNIONSTORE destination key1 [key2..]</code></td>
<td>在SUNION的基础上，存储结果到及和张。覆盖</td>
</tr>
<tr>
<td><code>SSCAN KEY [MATCH pattern] [COUNT count]</code></td>
<td>在大量数据环境下，使用此命令遍历集合中元素，每次遍历部分</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">---------------SADD--SCARD--SMEMBERS--SISMEMBER--------------------

127.0.0.1:6379&gt; SADD myset m1 m2 m3 m4 # 向myset中增加成员 m1~m4
(integer) 4
127.0.0.1:6379&gt; SCARD myset # 获取集合的成员数目
(integer) 4
127.0.0.1:6379&gt; smembers myset # 获取集合中所有成员
1) &quot;m4&quot;
2) &quot;m3&quot;
3) &quot;m2&quot;
4) &quot;m1&quot;
127.0.0.1:6379&gt; SISMEMBER myset m5 # 查询m5是否是myset的成员
(integer) 0 # 不是，返回0
127.0.0.1:6379&gt; SISMEMBER myset m2
(integer) 1 # 是，返回1
127.0.0.1:6379&gt; SISMEMBER myset m3
(integer) 1

---------------------SRANDMEMBER--SPOP----------------------------------

127.0.0.1:6379&gt; SRANDMEMBER myset 3 # 随机返回3个成员
1) &quot;m2&quot;
2) &quot;m3&quot;
3) &quot;m4&quot;
127.0.0.1:6379&gt; SRANDMEMBER myset # 随机返回1个成员
&quot;m3&quot;
127.0.0.1:6379&gt; SPOP myset 2 # 随机移除并返回2个成员
1) &quot;m1&quot;
2) &quot;m4&quot;
# 将set还原到{m1,m2,m3,m4}

---------------------SMOVE--SREM----------------------------------------

127.0.0.1:6379&gt; SMOVE myset newset m3 # 将myset中m3成员移动到newset集合
(integer) 1
127.0.0.1:6379&gt; SMEMBERS myset
1) &quot;m4&quot;
2) &quot;m2&quot;
3) &quot;m1&quot;
127.0.0.1:6379&gt; SMEMBERS newset
1) &quot;m3&quot;
127.0.0.1:6379&gt; SREM newset m3 # 从newset中移除m3元素
(integer) 1
127.0.0.1:6379&gt; SMEMBERS newset
(empty list or set)

# 下面开始是多集合操作,多集合操作中若只有一个参数默认和自身进行运算
# setx=&gt;{m1,m2,m4,m6}, sety=&gt;{m2,m5,m6}, setz=&gt;{m1,m3,m6}

-----------------------------SDIFF------------------------------------

127.0.0.1:6379&gt; SDIFF setx sety setz # 等价于setx-sety-setz
1) &quot;m4&quot;
127.0.0.1:6379&gt; SDIFF setx sety # setx - sety
1) &quot;m4&quot;
2) &quot;m1&quot;
127.0.0.1:6379&gt; SDIFF sety setx # sety - setx
1) &quot;m5&quot;


-------------------------SINTER---------------------------------------
# 共同关注（交集）

127.0.0.1:6379&gt; SINTER setx sety setz # 求 setx、sety、setx的交集
1) &quot;m6&quot;
127.0.0.1:6379&gt; SINTER setx sety # 求setx sety的交集
1) &quot;m2&quot;
2) &quot;m6&quot;

-------------------------SUNION---------------------------------------

127.0.0.1:6379&gt; SUNION setx sety setz # setx sety setz的并集
1) &quot;m4&quot;
2) &quot;m6&quot;
3) &quot;m3&quot;
4) &quot;m2&quot;
5) &quot;m1&quot;
6) &quot;m5&quot;
127.0.0.1:6379&gt; SUNION setx sety # setx sety 并集
1) &quot;m4&quot;
2) &quot;m6&quot;
3) &quot;m2&quot;
4) &quot;m1&quot;
5) &quot;m5&quot;
</code></pre>
<h3 id="hash-">Hash（哈希）</h3>
<p>Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象，Set就是一种简化的Hash,只变动key,而value使用默认值填充。可以将一个Hash表作为一个对象进行存储，表中存放对象的信息。</p>
<h4 id="-">应用场景</h4>
<p>1、由于hash数据类型的key-value的特性，用来存储关系型数据库中表记录，是redis中哈希类型最常用的场景。一条记录作为一个key-value，把每列属性值对应成field-value存储在哈希表当中，然后通过key值来区分表当中的主键。</p>
<p>2、经常被用来存储用户相关信息。优化用户信息的获取，不需要重复从数据库当中读取，提高系统性能。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>HSET key field value</code></td>
<td>将哈希表 key 中的字段 field 的值设为 value 。重复设置同一个field会覆盖,返回0</td>
</tr>
<tr>
<td><code>HMSET key field1 value1 [field2 value2..]</code></td>
<td>同时将多个 field-value (域-值)对设置到哈希表 key 中。</td>
</tr>
<tr>
<td><code>HSETNX key field value</code></td>
<td>只有在字段 field 不存在时，设置哈希表字段的值。</td>
</tr>
<tr>
<td><code>HEXISTS key field</code></td>
<td>查看哈希表 key 中，指定的字段是否存在。</td>
</tr>
<tr>
<td><code>HGET key field value</code></td>
<td>获取存储在哈希表中指定字段的值</td>
</tr>
<tr>
<td><code>HMGET key field1 [field2..]</code></td>
<td>获取所有给定字段的值</td>
</tr>
<tr>
<td><code>HGETALL key</code></td>
<td>获取在哈希表key 的所有字段和值</td>
</tr>
<tr>
<td><code>HKEYS key</code></td>
<td>获取哈希表key中所有的字段</td>
</tr>
<tr>
<td><code>HLEN key</code></td>
<td>获取哈希表中字段的数量</td>
</tr>
<tr>
<td><code>HVALS key</code></td>
<td>获取哈希表中所有值</td>
</tr>
<tr>
<td><code>HDEL key field1 [field2..]</code></td>
<td>删除哈希表key中一个/多个field字段</td>
</tr>
<tr>
<td><code>HINCRBY key field n</code></td>
<td>为哈希表 key 中的指定字段的整数值加上增量n，并返回增量后结果 一样只适用于整数型字段</td>
</tr>
<tr>
<td><code>HINCRBYFLOAT key field n</code></td>
<td>为哈希表 key 中的指定字段的浮点数值加上增量 n。</td>
</tr>
<tr>
<td><code>HSCAN key cursor [MATCH pattern] [COUNT count]</code></td>
<td>迭代哈希表中的键值对。</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">------------------------HSET--HMSET--HSETNX----------------
127.0.0.1:6379&gt; HSET studentx name sakura # 将studentx哈希表作为一个对象，设置name为sakura
(integer) 1
127.0.0.1:6379&gt; HSET studentx name gyc # 重复设置field进行覆盖，并返回0
(integer) 0
127.0.0.1:6379&gt; HSET studentx age 20 # 设置studentx的age为20
(integer) 1
127.0.0.1:6379&gt; HMSET studentx sex 1 tel 15623667886 # 设置sex为1，tel为15623667886
OK
127.0.0.1:6379&gt; HSETNX studentx name gyc # HSETNX 设置已存在的field
(integer) 0 # 失败
127.0.0.1:6379&gt; HSETNX studentx email 12345@qq.com
(integer) 1 # 成功

----------------------HEXISTS--------------------------------
127.0.0.1:6379&gt; HEXISTS studentx name # name字段在studentx中是否存在
(integer) 1 # 存在
127.0.0.1:6379&gt; HEXISTS studentx addr
(integer) 0 # 不存在

-------------------HGET--HMGET--HGETALL-----------
127.0.0.1:6379&gt; HGET studentx name # 获取studentx中name字段的value
&quot;gyc&quot;
127.0.0.1:6379&gt; HMGET studentx name age tel # 获取studentx中name、age、tel字段的value
1) &quot;gyc&quot;
2) &quot;20&quot;
3) &quot;15623667886&quot;
127.0.0.1:6379&gt; HGETALL studentx # 获取studentx中所有的field及其value
 1) &quot;name&quot;
 2) &quot;gyc&quot;
 3) &quot;age&quot;
 4) &quot;20&quot;
 5) &quot;sex&quot;
 6) &quot;1&quot;
 7) &quot;tel&quot;
 8) &quot;15623667886&quot;
 9) &quot;email&quot;
10) &quot;12345@qq.com&quot;


--------------------HKEYS--HLEN--HVALS--------------
127.0.0.1:6379&gt; HKEYS studentx # 查看studentx中所有的field
1) &quot;name&quot;
2) &quot;age&quot;
3) &quot;sex&quot;
4) &quot;tel&quot;
5) &quot;email&quot;
127.0.0.1:6379&gt; HLEN studentx # 查看studentx中的字段数量
(integer) 5
127.0.0.1:6379&gt; HVALS studentx # 查看studentx中所有的value
1) &quot;gyc&quot;
2) &quot;20&quot;
3) &quot;1&quot;
4) &quot;15623667886&quot;
5) &quot;12345@qq.com&quot;

-------------------------HDEL--------------------------
127.0.0.1:6379&gt; HDEL studentx sex tel # 删除studentx 中的sex、tel字段
(integer) 2
127.0.0.1:6379&gt; HKEYS studentx
1) &quot;name&quot;
2) &quot;age&quot;
3) &quot;email&quot;

-------------HINCRBY--HINCRBYFLOAT------------------------
127.0.0.1:6379&gt; HINCRBY studentx age 1 # studentx的age字段数值+1
(integer) 21
127.0.0.1:6379&gt; HINCRBY studentx name 1 # 非整数字型字段不可用
(error) ERR hash value is not an integer
127.0.0.1:6379&gt; HINCRBYFLOAT studentx weight 0.6 # weight字段增加0.6
&quot;90.8&quot;
</code></pre>
<p> Hash变更的数据user name age，尤其是用户信息之类的，经常变动的信息！Hash更适合于对象的存储，Sring更加适合字符串存储！</p>
<h3 id="zset-">Zset（有序集合）</h3>
<p>不同的是每个元素都会关联一个double类型的分数（score）。redis正是通过分数来为集合中的成员进行从小到大的排序。score相同：按字典顺序排序，有序集合的成员是唯一的，但分数(score)却可以重复。</p>
<h4 id="-">应用场景</h4>
<p>1、 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。</p>
<p>2、用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ZADD key score member1 [score2 member2]</code></td>
<td>向有序集合添加一个或多个成员，或者更新已存在成员的分数</td>
</tr>
<tr>
<td><code>ZCARD key</code></td>
<td>获取有序集合的成员数</td>
</tr>
<tr>
<td><code>ZCOUNT key min max</code></td>
<td>计算在有序集合中指定区间score的成员数</td>
</tr>
<tr>
<td><code>ZINCRBY key n member</code></td>
<td>有序集合中对指定成员的分数加上增量 n</td>
</tr>
<tr>
<td><code>ZSCORE key member</code></td>
<td>返回有序集中，成员的分数值</td>
</tr>
<tr>
<td><code>ZRANK key member</code></td>
<td>返回有序集合中指定成员的索引</td>
</tr>
<tr>
<td><code>ZRANGE key start end</code></td>
<td>通过索引区间返回有序集合成指定区间内的成员</td>
</tr>
<tr>
<td><code>ZRANGEBYLEX key min max</code></td>
<td>通过字典区间返回有序集合的成员</td>
</tr>
<tr>
<td><code>ZRANGEBYSCORE key min max</code></td>
<td>通过分数返回有序集合指定区间内的成员-inf 和 +inf分别表示最小最大值，只支持开区间()</td>
</tr>
<tr>
<td><code>ZLEXCOUNT key min max</code></td>
<td>在有序集合中计算指定字典区间内成员数量</td>
</tr>
<tr>
<td><code>ZREM key member1 [member2..]</code></td>
<td>移除有序集合中一个/多个成员</td>
</tr>
<tr>
<td><code>ZREMRANGEBYLEX key min max</code></td>
<td>移除有序集合中给定的字典区间的所有成员</td>
</tr>
<tr>
<td><code>ZREMRANGEBYRANK key start stop</code></td>
<td>移除有序集合中给定的排名区间的所有成员</td>
</tr>
<tr>
<td><code>ZREMRANGEBYSCORE key min max</code></td>
<td>移除有序集合中给定的分数区间的所有成员</td>
</tr>
<tr>
<td><code>ZREVRANGE key start end</code></td>
<td>返回有序集中指定区间内的成员，通过索引，分数从高到底</td>
</tr>
<tr>
<td><code>ZREVRANGEBYSCORRE key max min</code></td>
<td>返回有序集中指定分数区间内的成员，分数从高到低排序</td>
</tr>
<tr>
<td><code>ZREVRANGEBYLEX key max min</code></td>
<td>返回有序集中指定字典区间内的成员，按字典顺序倒序</td>
</tr>
<tr>
<td><code>ZREVRANK key member</code></td>
<td>返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序</td>
</tr>
<tr>
<td><code>ZINTERSTORE destination numkeys key1 [key2 ..]</code></td>
<td>计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中，numkeys：表示参与运算的集合数，将score相加作为结果的score</td>
</tr>
<tr>
<td><code>ZUNIONSTORE destination numkeys key1 [key2..]</code></td>
<td>计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中</td>
</tr>
<tr>
<td><code>ZSCAN key cursor [MATCH pattern\] [COUNT count]</code></td>
<td>迭代有序集合中的元素（包括元素成员和元素分值）</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">-------------------ZADD--ZCARD--ZCOUNT--------------
127.0.0.1:6379&gt; ZADD myzset 1 m1 2 m2 3 m3 # 向有序集合myzset中添加成员m1 score=1 以及成员m2 score=2..
(integer) 2
127.0.0.1:6379&gt; ZCARD myzset # 获取有序集合的成员数
(integer) 2
127.0.0.1:6379&gt; ZCOUNT myzset 0 1 # 获取score在 [0,1]区间的成员数量
(integer) 1
127.0.0.1:6379&gt; ZCOUNT myzset 0 2
(integer) 2

----------------ZINCRBY--ZSCORE--------------------------
127.0.0.1:6379&gt; ZINCRBY myzset 5 m2 # 将成员m2的score +5
&quot;7&quot;
127.0.0.1:6379&gt; ZSCORE myzset m1 # 获取成员m1的score
&quot;1&quot;
127.0.0.1:6379&gt; ZSCORE myzset m2
&quot;7&quot;

--------------ZRANK--ZRANGE-----------------------------------
127.0.0.1:6379&gt; ZRANK myzset m1 # 获取成员m1的索引，索引按照score排序，score相同索引值按字典顺序顺序增加
(integer) 0
127.0.0.1:6379&gt; ZRANK myzset m2
(integer) 2
127.0.0.1:6379&gt; ZRANGE myzset 0 1 # 获取索引在 0~1的成员
1) &quot;m1&quot;
2) &quot;m3&quot;
127.0.0.1:6379&gt; ZRANGE myzset 0 -1 # 获取全部成员
1) &quot;m1&quot;
2) &quot;m3&quot;
3) &quot;m2&quot;

#testset=&gt;{abc,add,amaze,apple,back,java,redis} score均为0
------------------ZRANGEBYLEX---------------------------------
127.0.0.1:6379&gt; ZRANGEBYLEX testset - + # 返回所有成员
1) &quot;abc&quot;
2) &quot;add&quot;
3) &quot;amaze&quot;
4) &quot;apple&quot;
5) &quot;back&quot;
6) &quot;java&quot;
7) &quot;redis&quot;
127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 0 3 # 分页 按索引显示查询结果的 0,1,2条记录
1) &quot;abc&quot;
2) &quot;add&quot;
3) &quot;amaze&quot;
127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 3 3 # 显示 3,4,5条记录
1) &quot;apple&quot;
2) &quot;back&quot;
3) &quot;java&quot;
127.0.0.1:6379&gt; ZRANGEBYLEX testset (- [apple # 显示 (-,apple] 区间内的成员
1) &quot;abc&quot;
2) &quot;add&quot;
3) &quot;amaze&quot;
4) &quot;apple&quot;
127.0.0.1:6379&gt; ZRANGEBYLEX testset [apple [java # 显示 [apple,java]字典区间的成员
1) &quot;apple&quot;
2) &quot;back&quot;
3) &quot;java&quot;

-----------------------ZRANGEBYSCORE---------------------
127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 10 # 返回score在 [1,10]之间的的成员
1) &quot;m1&quot;
2) &quot;m3&quot;
3) &quot;m2&quot;
127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 5
1) &quot;m1&quot;
2) &quot;m3&quot;

--------------------ZLEXCOUNT-----------------------------
127.0.0.1:6379&gt; ZLEXCOUNT testset - +
(integer) 7
127.0.0.1:6379&gt; ZLEXCOUNT testset [apple [java
(integer) 3

------------------ZREM--ZREMRANGEBYLEX--ZREMRANGBYRANK--ZREMRANGEBYSCORE--------------------------------
127.0.0.1:6379&gt; ZREM testset abc # 移除成员abc
(integer) 1
127.0.0.1:6379&gt; ZREMRANGEBYLEX testset [apple [java # 移除字典区间[apple,java]中的所有成员
(integer) 3
127.0.0.1:6379&gt; ZREMRANGEBYRANK testset 0 1 # 移除排名0~1的所有成员
(integer) 2
127.0.0.1:6379&gt; ZREMRANGEBYSCORE myzset 0 3 # 移除score在 [0,3]的成员
(integer) 2


# testset=&gt; {abc,add,apple,amaze,back,java,redis} score均为0
# myzset=&gt; {(m1,1),(m2,2),(m3,3),(m4,4),(m7,7),(m9,9)}
----------------ZREVRANGE--ZREVRANGEBYSCORE--ZREVRANGEBYLEX-----------
127.0.0.1:6379&gt; ZREVRANGE myzset 0 3 # 按score递减排序，然后按索引，返回结果的 0~3
1) &quot;m9&quot;
2) &quot;m7&quot;
3) &quot;m4&quot;
4) &quot;m3&quot;
127.0.0.1:6379&gt; ZREVRANGE myzset 2 4 # 返回排序结果的 索引的2~4
1) &quot;m4&quot;
2) &quot;m3&quot;
3) &quot;m2&quot;
127.0.0.1:6379&gt; ZREVRANGEBYSCORE myzset 6 2 # 按score递减顺序 返回集合中分数在[2,6]之间的成员
1) &quot;m4&quot;
2) &quot;m3&quot;
3) &quot;m2&quot;
127.0.0.1:6379&gt; ZREVRANGEBYLEX testset [java (add # 按字典倒序 返回集合中(add,java]字典区间的成员
1) &quot;java&quot;
2) &quot;back&quot;
3) &quot;apple&quot;
4) &quot;amaze&quot;

-------------------------ZREVRANK------------------------------
127.0.0.1:6379&gt; ZREVRANK myzset m7 # 按score递减顺序，返回成员m7索引
(integer) 1
127.0.0.1:6379&gt; ZREVRANK myzset m2
(integer) 4


# mathscore=&gt;{(xm,90),(xh,95),(xg,87)} 小明、小红、小刚的数学成绩
# enscore=&gt;{(xm,70),(xh,93),(xg,90)} 小明、小红、小刚的英语成绩
-------------------ZINTERSTORE--ZUNIONSTORE-----------------------------------
127.0.0.1:6379&gt; ZINTERSTORE sumscore 2 mathscore enscore # 将mathscore enscore进行合并 结果存放到sumscore
(integer) 3
127.0.0.1:6379&gt; ZRANGE sumscore 0 -1 withscores # 合并后的score是之前集合中所有score的和
1) &quot;xm&quot;
2) &quot;160&quot;
3) &quot;xg&quot;
4) &quot;177&quot;
5) &quot;xh&quot;
6) &quot;188&quot;

127.0.0.1:6379&gt; ZUNIONSTORE lowestscore 2 mathscore enscore AGGREGATE MIN # 取两个集合的成员score最小值作为结果的
(integer) 3
127.0.0.1:6379&gt; ZRANGE lowestscore 0 -1 withscores
1) &quot;xm&quot;
2) &quot;70&quot;
3) &quot;xg&quot;
4) &quot;87&quot;
5) &quot;xh&quot;
6) &quot;93&quot;
</code></pre>
<p>应用案例：</p>
<ul>
<li>set排序 存储班级成绩表 工资表排序！</li>
<li>普通消息，1.重要消息 2.带权重进行判断</li>
<li>排行榜应用实现，取Top N测试</li>
</ul>
<h2 id="-">三种特殊数据类型</h2>
<h3 id="geospatial-">Geospatial(地理位置)</h3>
<p>使用经纬度定位地理坐标并用一个有序集合zset保存，所以zset命令也可以使用。</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>geoadd key longitud(经度) latitude(纬度) member [..]</code></td>
<td>将具体经纬度的坐标存入一个有序集合</td>
</tr>
<tr>
<td><code>geopos key member [member..]</code></td>
<td>获取集合中的一个/多个成员坐标</td>
</tr>
<tr>
<td><code>geodist key member1 member2 [unit]</code></td>
<td>返回两个给定位置之间的距离。默认以米作为单位。</td>
</tr>
<tr>
<td>`georadius key longitude latitude radius m</td>
<td>km</td>
<td>mi</td>
<td>ft [WITHCOORD][WITHDIST] [WITHHASH] [COUNT count]`</td>
<td>以给定的经纬度为中心， 返回集合包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。</td>
</tr>
<tr>
<td><code>GEORADIUSBYMEMBER key member radius...</code></td>
<td>功能与GEORADIUS相同，只是中心位置不是具体的经纬度，而是使用结合中已有的成员作为中心点。</td>
</tr>
<tr>
<td><code>geohash key member1 [member2..]</code></td>
<td>返回一个或多个位置元素的Geohash表示。使用Geohash位置52点整数编码。</td>
</tr>
</tbody>
</table>
<p>有效经纬度</p>
<blockquote>
<ul>
<li>有效的经度从-180度到180度。</li>
<li>有效的纬度从-85.05112878度到85.05112878度。</li>
</ul>
</blockquote>
<p>指定单位的参数 <strong>unit</strong> 必须是以下单位的其中一个：</p>
<ul>
<li><strong>m</strong> 表示单位为米。</li>
<li><strong>km</strong> 表示单位为千米。</li>
<li><strong>mi</strong> 表示单位为英里。</li>
<li><strong>ft</strong> 表示单位为英尺。</li>
</ul>
<p>关于GEORADIUS的参数</p>
<blockquote>
<p>通过<code>georadius</code>就可以完成 附近的人功能</p>
<p>withcoord:带上坐标</p>
<p>withdist:带上距离，单位与半径单位相同</p>
<p>COUNT n : 只显示前n个(按距离递增排序)</p>
</blockquote>
<pre><code class="lang-bash">----------------georadius---------------------
127.0.0.1:6379&gt; GEORADIUS china:city 120 30 500 km withcoord withdist # 查询经纬度(120,30)坐标500km半径内的成员
1) 1) &quot;hangzhou&quot;
   2) &quot;29.4151&quot;
   3) 1) &quot;120.20000249147415&quot;
      2) &quot;30.199999888333501&quot;
2) 1) &quot;shanghai&quot;
   2) &quot;205.3611&quot;
   3) 1) &quot;121.40000134706497&quot;
      2) &quot;31.400000253193539&quot;

------------geohash---------------------------
127.0.0.1:6379&gt; geohash china:city yichang shanghai # 获取成员经纬坐标的geohash表示
1) &quot;wmrjwbr5250&quot;
2) &quot;wtw6ds0y300&quot;
</code></pre>
<h3 id="hyperloglog-">Hyperloglog(基数统计)</h3>
<p>Redis HyperLogLog 是用来做基数（数据集中不重复的元素的个数）统计的数据结构，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。</p>
<p>花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。</p>
<p>因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。</p>
<p>应用场景：网页的访问量（UV），一个用户多次访问，也只能算作一个人。</p>
<blockquote>
<p>传统实现，存储用户的id,然后每次进行比较。当用户变多之后这种方式及其浪费空间，而我们的目的只是计数，Hyperloglog就能帮助我们利用最小的空间完成。</p>
</blockquote>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>PFADD key element1 [elememt2..]</code></td>
<td>添加指定元素到 HyperLogLog 中</td>
</tr>
<tr>
<td><code>PFCOUNT key [key]</code></td>
<td>返回给定 HyperLogLog 的基数估算值。</td>
</tr>
<tr>
<td><code>PFMERGE destkey sourcekey [sourcekey..]</code></td>
<td>将多个 HyperLogLog 合并为一个 HyperLogLog</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">----------PFADD--PFCOUNT---------------------
127.0.0.1:6379&gt; PFADD myelemx a b c d e f g h i j k # 添加元素
(integer) 1
127.0.0.1:6379&gt; type myelemx # hyperloglog底层使用String
string
127.0.0.1:6379&gt; PFCOUNT myelemx # 估算myelemx的基数
(integer) 11
127.0.0.1:6379&gt; PFADD myelemy i j k z m c b v p q s
(integer) 1
127.0.0.1:6379&gt; PFCOUNT myelemy
(integer) 11

----------------PFMERGE-----------------------
127.0.0.1:6379&gt; PFMERGE myelemz myelemx myelemy # 合并myelemx和myelemy 成为myelemz
OK
127.0.0.1:6379&gt; PFCOUNT myelemz # 估算基数
(integer) 17
</code></pre>
<p>如果允许容错，那么一定可以使用Hyperloglog !</p>
<p>如果不允许容错，就使用set或者自己的数据类型即可 ！</p>
<h3 id="bitmaps-">BitMaps(位图)</h3>
<p>使用位存储，信息状态只有 0 和 1，Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。</p>
<p>应用场景：签到统计、状态统计</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>setbit key offset value</code></td>
<td>为指定key的offset位设置值</td>
</tr>
<tr>
<td><code>getbit key offset</code></td>
<td>获取offset位的值</td>
</tr>
<tr>
<td><code>bitcount key [start end]</code></td>
<td>统计字符串被设置为1的bit数，也可以指定统计范围按字节</td>
</tr>
<tr>
<td><code>bitop operration destkey key[key..]</code></td>
<td>对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。</td>
</tr>
<tr>
<td><code>BITPOS key bit [start] [end]</code></td>
<td>返回字符串里面第一个被设置为1或者0的bit位。start和end只能按字节,不能按位</td>
</tr>
</tbody>
</table>
<pre><code class="lang-bash">------------setbit--getbit--------------
127.0.0.1:6379&gt; setbit sign 0 1 # 设置sign的第0位为 1 
(integer) 0
127.0.0.1:6379&gt; setbit sign 2 1 # 设置sign的第2位为 1  不设置默认 是0
(integer) 0
127.0.0.1:6379&gt; setbit sign 3 1
(integer) 0
127.0.0.1:6379&gt; setbit sign 5 1
(integer) 0
127.0.0.1:6379&gt; type sign
string

127.0.0.1:6379&gt; getbit sign 2 # 获取第2位的数值
(integer) 1
127.0.0.1:6379&gt; getbit sign 3
(integer) 1
127.0.0.1:6379&gt; getbit sign 4 # 未设置默认是0
(integer) 0

-----------bitcount----------------------------
127.0.0.1:6379&gt; BITCOUNT sign # 统计sign中为1的位数
(integer) 4
</code></pre>
<p>这样设置以后你能get到的值是：\xA2\x80，所以bitmaps是一串从左到右的二进制串</p>
<h1 id="redis-">Redis事务</h1>
<p>Redis的事务就是指一组命令的集合，Redis的单条命令是保证原子性的，但是redis事务不能保证原子性，并且Redis事务没有隔离级别的概念。</p>
<p>事务中每条命令都会被序列化，执行过程中按顺序执行，不允许其他命令进行干扰。</p>
<ul>
<li>一次性</li>
<li>顺序性</li>
<li>排他性</li>
</ul>
<h2 id="-">操作过程</h2>
<ul>
<li>开启事务（<code>multi</code>）</li>
<li>命令入队</li>
<li>执行事务（<code>exec</code>）</li>
</ul>
<p>所以事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; multi # 开启事务
OK
127.0.0.1:6379&gt; set k1 v1 # 命令入队
QUEUED
127.0.0.1:6379&gt; set k2 v2 # ..
QUEUED
127.0.0.1:6379&gt; get k1
QUEUED
127.0.0.1:6379&gt; set k3 v3
QUEUED
127.0.0.1:6379&gt; keys *
QUEUED
127.0.0.1:6379&gt; exec # 事务执行
1) OK
2) OK
3) &quot;v1&quot;
4) OK
5) 1) &quot;k3&quot;
   2) &quot;k2&quot;
   3) &quot;k1&quot;
</code></pre>
<p>取消事务(discurd)</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; set k1 v1
QUEUED
127.0.0.1:6379&gt; set k2 v2
QUEUED
127.0.0.1:6379&gt; DISCARD # 放弃事务
OK
127.0.0.1:6379&gt; EXEC 
(error) ERR EXEC without MULTI # 当前未开启事务
127.0.0.1:6379&gt; get k1 # 被放弃事务中命令并未执行
(nil)
</code></pre>
<h2 id="-">事务错误</h2>
<p>代码语法错误（编译时异常）所有的命令都不执行：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; set k1 v1
QUEUED
127.0.0.1:6379&gt; set k2 v2
QUEUED
127.0.0.1:6379&gt; error k1 # 这是一条语法错误命令
(error) ERR unknown command `error`, with args beginning with: `k1`, # 会报错但是不影响后续命令入队 
127.0.0.1:6379&gt; get k2
QUEUED
127.0.0.1:6379&gt; EXEC
(error) EXECABORT Transaction discarded because of previous errors. # 执行报错
127.0.0.1:6379&gt; get k1 
(nil) # 其他命令并没有被执行
</code></pre>
<p>当代码逻辑错误 (运行时异常) ，其他命令可以正常执行，因此说Redis所以不保证事务原子性：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; set k1 v1
QUEUED
127.0.0.1:6379&gt; set k2 v2
QUEUED
127.0.0.1:6379&gt; INCR k1 # 这条命令逻辑错误（对字符串进行增量）
QUEUED
127.0.0.1:6379&gt; get k2
QUEUED
127.0.0.1:6379&gt; exec
1) OK
2) OK
3) (error) ERR value is not an integer or out of range # 运行时报错
4) &quot;v2&quot; # 其他命令正常执行

# 虽然中间有一条命令报错了，但是后面的指令依旧正常执行成功了。
# 所以说Redis单条指令保证原子性，但是Redis事务不能保证原子性。
</code></pre>
<h2 id="-">监控</h2>
<p>使用<code>watch key</code>监控指定数据，相当于乐观锁加锁。</p>
<p>正常执行：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; set money 100 # 设置余额:100
OK
127.0.0.1:6379&gt; set use 0 # 支出使用:0
OK
127.0.0.1:6379&gt; watch money # 监视money (上锁)
OK
127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; DECRBY money 20
QUEUED
127.0.0.1:6379&gt; INCRBY use 20
QUEUED
127.0.0.1:6379&gt; exec # 监视值没有被中途修改，事务正常执行
1) (integer) 80
2) (integer) 20
</code></pre>
<p>测试多线程修改值，使用watch可以当做redis的乐观锁操作（相当于getversion）：</p>
<p>我们启动另外一个客户端模拟插队线程。</p>
<p>线程1：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; watch money # money上锁
OK
127.0.0.1:6379&gt; multi
OK
127.0.0.1:6379&gt; DECRBY money 20
QUEUED
127.0.0.1:6379&gt; INCRBY use 20
QUEUED
127.0.0.1:6379&gt;     # 此时事务并没有执行
</code></pre>
<p>模拟线程插队，线程2：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; INCRBY money 500 # 修改了线程一中监视的money
(integer) 600
12
</code></pre>
<p>回到线程1，执行事务：</p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; EXEC # 执行之前，另一个线程修改了我们的值，这个时候就会导致事务执行失败
(nil) # 没有结果，说明事务执行失败

127.0.0.1:6379&gt; get money # 线程2 修改生效
&quot;600&quot;
127.0.0.1:6379&gt; get use # 线程1事务执行失败，数值没有被修改
&quot;0&quot;
</code></pre>
<p>解锁获取最新值，然后再加锁进行事务。<code>unwatch</code>进行解锁。注意：每次提交执行exec后都会自动释放锁，不管是否成功</p>
<p># </p>
<h1 id="-">持久化策略</h1>
<p>Redis支持RDB和AOF两种持久化机制，持久化功能有效避免因进程退出造成的数据丢失问题，当下次重启时利用之前持久化的文件即可实现数据恢复。</p>
<h2 id="rdb-">RDB持久化</h2>
<h3 id="-rdb">什么是RDB</h3>
<p>RDB持久化是把当前进程数据生成快照保存到硬盘的过程，触发RDB持久化过程可以分为手动触发和自动触发。默认情况下， Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。文件名可以在配置文件中进行自定义。</p>
<h3 id="-">工作原理</h3>
<p>RDB的手动触发分别对应save和bgsave命令：</p>
<ul>
<li>save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的示例会造成长时间则色，线上环境不建议使用。</li>
<li>bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。</li>
</ul>
<p>显然bgsave命令是针对save阻塞问题做的优化。因此Redis内部所有的涉及RDB的操作都采用bgsave的方式，而save命令已经废弃，因此这里不做过多介绍。</p>
<p>RDB的自动触发只需要在配置文件redis.conf中开启相关配置即可：</p>
<pre><code class="lang-bash">save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存
save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存
save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存
</code></pre>
<h4 id="bgsave">bgsave</h4>
<p>bgsave是异步进行，进行持久化的时候，Redis还可以将继续响应客户端请求 ；</p>
<p>详细具体步骤如下：</p>
<ul>
<li>执行bgsave命令，Redis父进程判断当前是否存在正在执行的子进程，如RDB/AOF子进程，如果存在bgsave命令直接返回</li>
<li>父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞，通过<code>info stats</code>命令查看<code>latest_fork_usec</code>选项，可以获取最近一个fork操作的耗时，单位为微秒</li>
<li>父进程fork完成后，bgsave命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令</li>
<li>父进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。执行<code>lastsave</code>命令可以获取最后一次生成RDB的时间，对应info统计的rdb_last_save_time选项</li>
<li>进程发送信号给父进程表示完成，父进程更新统计信息</li>
</ul>
<p>这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益(因为是使用子进程进行写操作，而父进程依然可以接收来自客户端的请求)。</p>
<h4 id="bgsave-save-">bgsave和save对比</h4>
<table>
<thead>
<tr>
<th>命令</th>
<th>save</th>
<th>bgsave</th>
</tr>
</thead>
<tbody>
<tr>
<td>IO类型</td>
<td>同步</td>
<td>异步</td>
</tr>
<tr>
<td>阻塞</td>
<td>是</td>
<td>是（阻塞发生在fock()，通常非常快）</td>
</tr>
<tr>
<td>复杂度</td>
<td>O(n)</td>
<td>O(n)</td>
</tr>
<tr>
<td>优点</td>
<td>不会消耗额外的内存</td>
<td>不阻塞客户端命令</td>
</tr>
<tr>
<td>缺点</td>
<td>阻塞客户端命令</td>
<td>需要fork子进程，消耗内存</td>
</tr>
</tbody>
</table>
<h3 id="-">优点和缺点</h3>
<p>优点：</p>
<ul>
<li>适合大规模的数据恢复</li>
<li>对数据的完整性要求不高</li>
<li>Redis加载RDB恢复数据远远快于AOF的方式</li>
</ul>
<p>缺点：</p>
<ul>
<li>需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改的数据就没有了</li>
<li>fork进程的时候，会占用一定的内存空间</li>
<li>RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容RDB格式的问题</li>
</ul>
<div class="note info"><p>也可以简单的说，RDB不适合实时持久化。</p></div>

<h2 id="-aof">持久化AOF</h2>
<p>AOF表示Append Only File，这种模式会将所有的命令都记录下来，恢复的时候就把这个文件全部再执行一遍。</p>
<blockquote>
<p>以日志的形式来记录每个写的操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。</p>
</blockquote>
<h3 id="-aof">什么是AOF</h3>
<p>快照功能（RDB）并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、以及未保存到快照中的那些数据。 从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化。</p>
<p>AOF默认是不开启的，需要进行配置才可以：</p>
<pre><code class="lang-bash">appendonly yes  # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分的情况下，rdb完全够用
appendfilename &quot;appendonly.aof&quot;

# appendfsync always # 每次修改都会sync 消耗性能
appendfsync everysec # 每秒执行一次 sync 可能会丢失这一秒的数据
# appendfsync no # 不执行 sync ,这时候操作系统自己同步数据，速度最快
</code></pre>
<h3 id="-">优点和缺点</h3>
<p>优点</p>
<ol>
<li>每一次修改都会同步，文件的完整性会更加好</li>
<li>没秒同步一次，可能会丢失一秒的数据</li>
<li>从不同步，效率最高</li>
</ol>
<p>缺点</p>
<ol>
<li>相对于数据文件来说，AOF远远大于RDB，修复速度比RDB慢</li>
<li>AOF运行效率也要比RDB慢，所以我们Redis默认的配置就是RDB持久化</li>
</ol>
<h2 id="rdb-aop-">RDB和AOP选择</h2>
<h3 id="rdb-aof-">RDB 和 AOF 对比</h3>
<table>
<thead>
<tr>
<th>比较项</th>
<th>RDB</th>
<th>AOF</th>
</tr>
</thead>
<tbody>
<tr>
<td>启动优先级</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>体积</td>
<td>小</td>
<td>大</td>
</tr>
<tr>
<td>恢复速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>数据安全性</td>
<td>丢数据</td>
<td>根据策略决定</td>
</tr>
</tbody>
</table>
<h3 id="-">如何选择使用哪种持久化方式？</h3>
<p>一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。</p>
<h1 id="redis-">Redis发布与订阅</h1>
<p>Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。</p>
<p>下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215523258.png" alt="在这里插入图片描述"></p>
<p>当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：</p>
<p><img src="https://img-blog.csdnimg.cn/2020051321553483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="-">命令</h2>
<table>
<thead>
<tr>
<th>命令</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>PSUBSCRIBE pattern [pattern..]</code></td>
<td>订阅一个或多个符合给定模式的频道。</td>
</tr>
<tr>
<td><code>PUNSUBSCRIBE pattern [pattern..]</code></td>
<td>退订一个或多个符合给定模式的频道。</td>
</tr>
<tr>
<td><code>PUBSUB subcommand [argument[argument]]</code></td>
<td>查看订阅与发布系统状态。</td>
</tr>
<tr>
<td><code>PUBLISH channel message</code></td>
<td>向指定频道发布消息</td>
</tr>
<tr>
<td><code>SUBSCRIBE channel [channel..]</code></td>
<td>订阅给定的一个或多个频道。</td>
</tr>
<tr>
<td><code>SUBSCRIBE channel [channel..]</code></td>
<td>退订一个或多个频道</td>
</tr>
</tbody>
</table>
<h2 id="-">示例</h2>
<pre><code class="lang-bash">------------订阅端----------------------
127.0.0.1:6379&gt; SUBSCRIBE sakura # 订阅sakura频道
Reading messages... (press Ctrl-C to quit) # 等待接收消息
1) &quot;subscribe&quot; # 订阅成功的消息
2) &quot;sakura&quot;
3) (integer) 1
1) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello world&quot;
2) &quot;sakura&quot;
3) &quot;hello world&quot;
1) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello i am sakura&quot;
2) &quot;sakura&quot;
3) &quot;hello i am sakura&quot;

--------------消息发布端-------------------
127.0.0.1:6379&gt; PUBLISH sakura &quot;hello world&quot; # 发布消息到sakura频道
(integer) 1
127.0.0.1:6379&gt; PUBLISH sakura &quot;hello i am sakura&quot; # 发布消息
(integer) 1

-----------------查看活跃的频道------------
127.0.0.1:6379&gt; PUBSUB channels
1) &quot;sakura&quot;
</code></pre>
<h2 id="-">原理</h2>
<p>每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h/redisServer 结构， 结构的 pubsub_channels 属性是一个字典， 这个字典就用于保存订阅频道的信息，其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。</p>
<p><img src="https://img-blog.csdnimg.cn/2020051321554964.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>客户端订阅，就被链接到对应频道的链表的尾部，退订则就是将客户端节点从链表中移除。</p>
<h2 id="-">缺点</h2>
<ol>
<li>如果一个客户端订阅了频道，但自己读取消息的速度却不够快的话，那么不f/断积压的消息会使redis输出缓冲区的体积变得越来越大，这可能使得redis本身的速度变慢，甚至直接崩溃。</li>
<li>这和数据传输可靠性有关，如果在订阅方断线，那么他将会丢失所有在短线期间发布者发布的消息。</li>
</ol>
<h2 id="-f-">应用.消息订阅：公众号订阅，微博关注等等（起始更多是使用消息‘f/队列来进行实现）</h2>
<ol start="2">
<li>多人在线聊天室。</li>
</ol>
<p>稍微复杂的场景，我们就会使用消息中间件MQ处理。</p>
<h1 id="redis-io-">Redis线程IO模型</h1>
<p>在从前的版本中，Redis是个单线程的程序，除了Redis之外，Node.js与Nginx也是单线程，但是它们都是高性能服务器的典范，不过从Redis6.0开始，增加了多线程的支持，以满足更高的性能，具体可以参考：<a href="https://stor.51cto.com/art/202005/616005.htm">支持多线程的Redis 6.0终于发布了</a>，那么Redis是如何使用单线程处理那么多的并发客户端连接的？答案就是多路复用。</p>
<h2 id="-io">非阻塞IO</h2>
<p>当我们调用套节字的读写方法，默认它们是阻塞的，比如read方法要传递进去一个参数n，表示读取这么多字节后再返回，如果没有读够线程就会卡在那里，直到新的数据刀来或者连接关闭了，read方法才会返回，线程才能继续处理。而write方法一般来说不会阻塞，除非内核为套接字分配的写缓冲区已经满了，write方法就会阻塞，直到缓存区中有空闲空间挪出来了。</p>
<p>非阻塞IO在套接字对象上提供了一个线程<code>Non_Blocking</code>，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。能读多少取决于内核为套接字分配的读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。</p>
<p>有了非阻塞IO意味着线程在读写IO时可以不必再阻塞了，读写可以瞬间完成然后程序可以继续干别的事了。</p>
<h2 id="-">多路复用</h2>
<p>非阻塞IO有个问题，那就是线程要读数据，结果读了一部分就返回了，线程如何知道何时才应该继续。也就是当数据到来时，线程如何得到通知。写也是一样，如果缓冲区满了，写不完，剩下的数据何时才应该续写，线程也应该得到通知。</p>
<p>多路复用（事件轮询）API就是用来解决这个问题的，最简单的事件轮询API是select函数，它是操作系统提供给用户程序的API。输入是读写描述符列表read_fds &amp; write_fds，输出是与之对应的可读可写事件。同时还提供了timeout参数，如果没有任何事件到来，那么久最多等待timeout时间，线程处于阻塞状态。一旦期间有任何事情刀来，就可以立即返回。时间过了之后还是没有任何事件到来，也会立即返回。拿到事件后，线程就可以继续挨个处理相应的事件。处理完了继续过来轮询。于是线程就进入了一个死循环，我们把这个死循环称为事件循环，一个循环为一个周期。</p>
<p>每个客户端套接字socket都有对应的读写文件描述符。</p>
<pre><code class="lang-python">read_events,write_events = select(read_fds,write_fds,timeout)
for event in read_events:
    handle_read(event.fd)
for event in write_events:
    handle_write(event.fd)
# 处理其它事情，如定时任务等
handle_others()
</code></pre>
<p>因为我们通过select系统调用同时处理多个通道描述符的读写事件，因此我们将这类系统调用称为多路复用API。现代操作系统的多路复用API已经不再使用使用select系统调用，而改用epoll(linux)和kqueue(freebsd &amp; macosx)，因为select系统调用的性能再描述符特别多时性能会非常差。它使用起来可能在形式上略有差异，但是本质上都是差不多的，都可以使用上面的伪代码逻辑进行理解。</p>
<h2 id="-">指令队列</h2>
<p>Redis会将每个客户端套接字都关联一个指令队列。客户端的指令通过队列来排队进行顺序处理，先到先服务。</p>
<h2 id="-">响应队列</h2>
<p>Redis同样会为每个客户端套接字关联一个响应队列。Redis服务器通过响应队列来将指令的返回结果回复给客户端。如果队列为空，那么意味着连接暂时处于空闲状态，不需要去获取写事件，也就是可以将当前的客户端描述符<code>write_fds</code>里面移出来。等到队列有数据了，再将描述符放进去。避免select系统调用立即返回写事件，结果发现没什么数据可以写。出现这种情况的线程会飙高CPU。</p>
<h1 id="redis-">Redis主从复制</h1>
<h2 id="-">概念</h2>
<p> 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master/Leader）,后者称为从节点（Slave/Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。</p>
<p>默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。</p>
<h2 id="-">作用</h2>
<ol>
<li>数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余的方式。</li>
<li>故障恢复：当主节点故障时，从节点可以暂时替代主节点提供服务，是一种服务冗余的方式</li>
<li>负载均衡：在主从复制的基础上，配合读写分离，由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量。</li>
<li>高可用基石：主从复制还是哨兵和集群能够实施的基础。</li>
</ol>
<h2 id="-">为什么使用集群</h2>
<ol>
<li>单台服务器难以负载大量的请求</li>
<li>单台服务器故障率高，系统崩坏概率大</li>
<li>单台服务器内存容量有限。</li>
</ol>
<h2 id="-">环境配置</h2>
<p>我们在讲解配置文件的时候，注意到有一个<code>replication</code>模块 (见Redis.conf中第8条)</p>
<p>查看当前库的信息：<code>info replication</code></p>
<pre><code class="lang-bash">127.0.0.1:6379&gt; info replication
# Replication
role:master # 角色
connected_slaves:0 # 从机数量
master_replid:3b54deef5b7b7b7f7dd8acefa23be48879b4fcff
master_replid2:0000000000000000000000000000000000000000
master_repl_offset:0
second_repl_offset:-1
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0
</code></pre>
<p>既然需要启动多个服务，就需要多个配置文件。每个配置文件对应修改以下信息：</p>
<ul>
<li>端口号</li>
<li>pid文件名</li>
<li>日志文件名</li>
<li>rdb文件名</li>
</ul>
<p>启动单机多服务集群：</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215610163.png" alt="在这里插入图片描述"></p>
<h2 id="-">一主二从配置</h2>
<p>默认情况下，每台Redis服务器都是主节点；我们一般情况下只用配置从机就好了！</p>
<p>认老大！一主（79）二从（80，81）</p>
<p>使用<code>SLAVEOF host port</code>就可以为从机配置主机了。</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215637483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /></p>
<p>然后主机上也能看到从机的状态：</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215645778.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /></p>
<p>我们这里是使用命令搭建，是暂时的，==真实开发中应该在从机的配置文件中进行配置，==这样的话是永久的。</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215654634.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="-">使用规则</h2>
<ol>
<li><p>从机只能读，不能写，主机可读可写但是多用于写。</p>
<pre><code class="lang-bash"> 127.0.0.1:6381&gt; set name sakura # 从机6381写入失败
(error) READONLY You can&#39;t write against a read only replica.

127.0.0.1:6380&gt; set name sakura # 从机6380写入失败
(error) READONLY You can&#39;t write against a read only replica.

127.0.0.1:6379&gt; set name sakura
OK
127.0.0.1:6379&gt; get name
&quot;sakura&quot;
</code></pre>
</li>
<li><p>当主机断电宕机后，默认情况下从机的角色不会发生变化 ，集群中只是失去了写操作，当主机恢复以后，又会连接上从机恢复原状。</p>
</li>
<li><p>当从机断电宕机后，若不是使用配置文件配置的从机，再次启动后作为主机是无法获取之前主机的数据的，若此时重新配置称为从机，又可以获取到主机的所有数据。这里就要提到一个同步原理。</p>
</li>
<li><p>第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机：</p>
<ul>
<li>从机手动执行命令<code>slaveof no one</code>,这样执行以后从机会独立出来成为一个主机</li>
<li>使用哨兵模式（自动选举）</li>
</ul>
</li>
</ol>
<blockquote>
<p>如果没有老大了，这个时候能不能选择出来一个老大呢？手动！</p>
</blockquote>
<p>如果主机断开了连接，我们可以使用<code>SLAVEOF no one</code>让自己变成主机！其他的节点就可以手动连接到最新的主节点（手动）！如果这个时候老大修复了，那么久重新连接！</p>
<h2 id="-">增量复制</h2>
<p>主从服务器在完成第一次同步后，就会基于长连接进行命令传播。</p>
<p>可是，网络总是不按套路出牌的嘛，说延迟就延迟，说断开就断开。</p>
<p>如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/4845008abadaa871613873f5ffdcb542.png" alt="图片"></p>
<p>那么问题来了，如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？</p>
<p>在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。</p>
<p>所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用<strong>增量复制</strong>的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。</p>
<p>网络恢复后的增量复制过程如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/e081b470870daeb763062bb873a4477e.png" alt="图片"></p>
<p>主要有三个步骤：</p>
<ul>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li>
<li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li>
</ul>
<p>那么关键的问题来了，<strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong></p>
<p>答案藏在这两个东西里：</p>
<ul>
<li><strong>repl_backlog_buffer</strong>，是一个「<strong>环形</strong>」缓冲区，用于主从服务器断连后，从中找到差异的数据；</li>
<li><strong>replication offset</strong>，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「<em>写</em>」到的位置，从服务器使用 slave_repl_offset 来记录自己「<em>读</em>」到的位置。</li>
</ul>
<p>那repl_backlog_buffer 缓冲区是什么时候写入的呢？</p>
<p>在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。</p>
<p>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：</p>
<ul>
<li>如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>增量同步</strong>的方式；</li>
<li>相反，如果判断出从服务器要读取的数据已经不存在 
repl_backlog_buffer 缓冲区里，那么主服务器将采用<strong>全量同步</strong>的方式。</li>
</ul>
<p>当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/2db4831516b9a8b79f833cf0593c1f12.png" alt="图片"></p>
<p>repl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。</p>
<p>因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。</p>
<p>那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。</p>
<p>因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。</p>
<p>那 repl_backlog_buffer 缓冲区具体要调整到多大呢？</p>
<p>repl_backlog_buffer 最小的大小可以根据这面这个公式估算。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/5e9e65a4a59b3688fa37cadbd87bb5ac.png" alt="图片"></p>
<p>我来解释下这个公式的意思：</p>
<ul>
<li>second 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。</li>
<li>write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。</li>
</ul>
<p>举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。</p>
<p>那么 repl_backlog_buffer 大小就不能低于 5 MB，否则新写地命令就会覆盖旧数据了。</p>
<p>当然，为了应对一些突发的情况，可以将 repl_backlog_buffer 的大小设置为此基础上的 2 倍，也就是 10 MB。</p>
<p>关于 repl_backlog_buffer 大小修改的方法，只需要修改配置文件里下面这个参数项的值就可以。</p>
<pre><code>repl-backlog-size 1mb
</code></pre><h2 id="-">总结</h2>
<p>主从复制共有三种模式：<strong>全量复制、基于长连接的命令传播、增量复制</strong>。</p>
<p>主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。</p>
<p>第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。</p>
<p>如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。</p>
<p>如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。</p>
<p>主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成的，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成，如下图所示：</p>
<h1 id="-">哨兵模式</h1>
<h2 id="-">作用</h2>
<p>主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。</p>
<h2 id="-">单机单个哨兵</h2>
<p>哨兵的作用：</p>
<ul>
<li>通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。</li>
<li>当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。</li>
</ul>
<h2 id="-">多哨兵模式</h2>
<p>Redis的主从复制模式可以将主节点的数据改变同步给从节点，这样从节点就可以起到两个作用：</p>
<ul>
<li>作为主节点的备份，一旦主节点出了故障不可达的情况，从节点可以作为后备“顶上来”，并且保证数据尽量不丢失（主从复制时最终一致性）。第二，从节点可以扩展主节点的读能力，一旦主节点不能支撑住大并发量的读操作</li>
<li>第二，从节点可以扩展主节点的读能力，一旦主节点不能支撑住大并发量的读操作，从节点可以在以顶程度上帮助主节点分担读压力</li>
</ul>
<p>但是主从复制也带来了以下问题：</p>
<ul>
<li>一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预</li>
<li>主节点的写能力收到单机的限制</li>
<li>主节点的存储能力收到单机的限制</li>
</ul>
<p>当主节点出现故障时，Redis的哨兵模式能自动完成故障发现和故障转移，并通知应用方，从而实现真正的高可用。Redis Sentinel是一个分布式架构，其中包含了若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点但做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。整个过程完全时自动的，不需要人工来介入，所以这套方案很有效地解决了Redis高可用的问题。</p>
<p>哨兵的核心配置</p>
<pre><code>sentinel monitor mymaster 127.0.0.1 6379 1
</code></pre><ul>
<li>数字1表示 ：当一个哨兵主观认为主机断开，就可以客观认为主机故障，然后开始选举新的主机。</li>
</ul>
<blockquote>
<p>测试</p>
</blockquote>
<pre><code>redis-sentinel xxx/sentinel.conf
</code></pre><p>成功启动哨兵模式</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215752444.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /></p>
<p>此时哨兵监视着我们的主机6379，当我们断开主机后：</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215806972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" /></p>
<h2 id="-">哨兵模式优缺点</h2>
<h3 id="-">优点</h3>
<ol>
<li>哨兵集群，基于主从复制模式，所有主从复制的优点，它都有</li>
<li>主从可以切换，故障可以转移，系统的可用性更好</li>
<li>哨兵模式是主从模式的升级，手动到自动，更加健壮</li>
</ol>
<h3 id="-">缺点</h3>
<ol>
<li>Redis不好在线扩容，集群容量一旦达到上限，在线扩容就十分麻烦</li>
<li>实现哨兵模式的配置其实是很麻烦的，里面有很多配置项</li>
</ol>
<p>完整的哨兵模式配置文件 sentinel.conf</p>
<pre><code class="lang-bash"># Example sentinel.conf

# 哨兵sentinel实例运行的端口 默认26379
port 26379

# 哨兵sentinel的工作目录
dir /tmp

# 哨兵sentinel监控的redis主节点的 ip port 
# master-name  可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。
# quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了
# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;
sentinel monitor mymaster 127.0.0.1 6379 1

# 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码
# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码
# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;
sentinel auth-pass mymaster MySUPER--secret-0123passw0rd


# 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒
# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;
sentinel down-after-milliseconds mymaster 30000

# 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，
这个数字越小，完成failover所需的时间就越长，
但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。
可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。
# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;
sentinel parallel-syncs mymaster 1



# 故障转移的超时时间 failover-timeout 可以用在以下这些方面： 
#1. 同一个sentinel对同一个master两次failover之间的间隔时间。
#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。
#3.当想要取消一个正在进行的failover所需要的时间。  
#4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了
# 默认三分钟
# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;
sentinel failover-timeout mymaster 180000

# SCRIPTS EXECUTION

#配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。
#对于脚本的运行结果有以下规则：
#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10
#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。
#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。
#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。

#通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，
#这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，
#一个是事件的类型，
#一个是事件的描述。
#如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。
#通知脚本
# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;
  sentinel notification-script mymaster /var/redis/notify.sh

# 客户端重新配置主节点参数脚本
# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。
# 以下参数将会在调用脚本时传给脚本:
# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;
# 目前&lt;state&gt;总是“failover”,
# &lt;role&gt;是“leader”或者“observer”中的一个。 
# 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的
# 这个脚本应该是通用的，能被多次调用，不是针对性的。
# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;
sentinel client-reconfig-script mymaster /var/redis/reconfig.sh
</code></pre>
<p>Redis当中使用了<a href="https://zhuanlan.zhihu.com/p/32052223">Raft算法</a>实现领导者选举。</p>
<h1 id="-">缓存穿透与雪崩</h1>
<h2 id="-">缓存穿透</h2>
<h3 id="-">概念</h3>
<p>在默认情况下，用户请求数据时，会先在缓存(Redis)中查找，若没找到即缓存未命中，再在数据库中进行查找，数量少可能问题不大，可是一旦大量的请求数据（例如秒杀场景）缓存都没有命中的话，就会全部转移到数据库上，造成数据库极大的压力，就有可能导致数据库崩溃。网络安全中也有人恶意使用这种手段进行攻击被称为洪水攻击。</p>
<h3 id="-">解决方案</h3>
<p>布隆过滤器：对所有可能查询的参数以Hash的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。</p>
<p>缓存空对象:一次请求若在缓存和数据库中都没找到，就在缓存中方一个空对象用于处理后续这个请求。</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215836317.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;" /></p>
<p> 这样做有一个缺陷：存储空对象也需要空间，大量的空对象会耗费一定的空间，存储效率并不高。解决这个缺陷的方式就是设置较短过期时间</p>
<p>即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。</p>
<h2 id="-">缓存击穿</h2>
<h3 id="-">概念</h3>
<p> 相较于缓存穿透，缓存击穿的目的性更强，一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。这就是缓存被击穿，只是针对其中某个key的缓存不可用而导致击穿，但是其他的key依然可以使用缓存响应。</p>
<p> 比如热搜排行上，一个热点新闻被同时大量访问就可能导致缓存击穿。</p>
<h3 id="-">解决方案</h3>
<ol>
<li><p>设置热点数据永不过期</p>
<p>这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。</p>
</li>
<li><p>加互斥锁(分布式锁)</p>
<p>在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。保证同时刻只有一个线程访问。这样对锁的要求就十分高。</p>
</li>
</ol>
<h2 id="-">缓存雪崩</h2>
<h3 id="-">概念</h3>
<p>大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。</p>
<p><img src="https://img-blog.csdnimg.cn/20200513215850428.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzg3MzIyNw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 67%;" /></p>
<h3 id="-">解决方案</h3>
<ul>
<li><p>redis高可用</p>
<p>这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群</p>
</li>
<li><p>限流降级</p>
<p>这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</p>
</li>
<li><p>数据预热</p>
<p>数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。</p>
</li>
</ul>
<h1 id="-">为什么需要分布式锁</h1>
<p>  我们前面文章<a href="https://zhuanlan.zhihu.com/p/422894836">synchronized同步锁的使用与原理</a>中已经讲过了synchronized的作用及原理，知道了synchronized是一把对象锁，当多个线程并发操作某个对象时，可以通过synchronized来保证同一时刻只能有一个线程获取到对象锁进而处理synchronized关键字修饰的代码块或方法。既然已经有了synchronized锁，为什么这里又要引入分布式锁呢？</p>
<p>  因为现在的系统基本都是分布式部署的，一个应用会被部署到多台服务器上，synchronized只能控制当前服务器自身的线程安全，并不能跨服务器控制并发安全。比如下图，同一时刻有4个线程新增同一件商品，其中两个线程由服务器A处理，另外两个线程由服务器B处理，那么最后的结果就是两台服务器各执行了一次新增动作。这显然不符合预期。</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-1fdf74426fc0be1a73c1e519b98b5215_720w.jpg" alt="img"></p>
<p>  而本篇文章要介绍的分布式锁就是为了解决这种问题的。</p>
<h2 id="-">什么是分布式锁</h2>
<p>  分布式锁，就是控制分布式系统中不同进程共同访问同一共享资源的一种锁的实现。</p>
<p>  所谓当局者迷，旁观者清，先举个生活中的例子，就拿高铁举例，每辆高铁都有自己的运行路线，但这些路线可能会与其他高铁的路线重叠，如果只让高铁内部的司机操控路线，那就可能出现撞车事故，因为司机不知道其他高铁的运行路线是什么。所以，中控室就发挥作用了，中控室会监控每辆高铁，高铁在什么时间走什么样的路线全部由中控室指挥。</p>
<p>  分布式锁就是基于这种思想实现的，它需要在我们分布式应用的外面使用一个第三方组件（可以是数据库、Redis、Zookeeper等）进行全局锁的监控，由这个组件决定什么时候加锁，什么时候释放锁。</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-fa7505da2b7e18c2ffd8f0c0ea966fa5_720w.jpg" alt="img"></p>
<h2 id="redis-">Redis如何实现分布式锁</h2>
<p>  在聊Redis如何实现分布式锁之前，我们要先聊一下redis的一个命令：setnx key value。我们知道，Redis设置一个key最常用的命令是：set key value，该命令不管key是否存在，都会将key的值设置成value，并返回成功：</p>
<p>  <img src="https://pic1.zhimg.com/80/v2-3eac58b4b844c5902fc78b27096c0038_720w.jpg" alt="img"></p>
<p>  setnx key value 也是设置key的值为value，不过，它会先判断key是否已经存在，如果key不存在，那么就设置key的值为value，并返回1；如果key已经存在，则不更新key的值，直接返回0：</p>
<p>  <img src="https://pic3.zhimg.com/80/v2-73ce24e3a8bfd6f9b12ad8d460c02012_720w.jpg" alt="img"></p>
<p>  ● <strong>最简单的版本：setnx key value</strong></p>
<p>  基于setnx命令的特性，我们就可以实现一个最简单的分布式锁了。我们通过向Redis发送 setnx 命令，然后判断Redis返回的结果是否为1，结果是1就表示setnx成功了，那本次就获得锁了，可以继续执行业务逻辑；如果结果是0，则表示setnx失败了，那本次就没有获取到锁，可以通过循环的方式一直尝试获取锁，直至其他客户端释放了锁（delete掉key）后，就可以正常执行setnx命令获取到锁。流程如下：</p>
<p>  <img src="https://pic3.zhimg.com/80/v2-f83fde65985ba7ea7e9bef88339bca4a_720w.jpg" alt="img"></p>
<p>  这种方式虽然实现了分布式锁的功能，但有一个很明显的问题：没有给key设置过期时间，万一程序在发送delete命令释放锁之前宕机了，那么这个key就会永久的存储在Redis中了，其他客户端也永远获取不到这把锁了。</p>
<p>  <strong>● 升级版本：设置key的过期时间</strong></p>
<p>  针对上面的问题，我们可以基于setnx key value的基础上，同时给key设置一个过期时间。Redis已经提供了这样的命令：set key value ex seconds nx。其中，ex seconds 表示给key设置过期时间，单位为秒，nx 表示该set命令具备setnx的特性。效果如下：</p>
<p>  <img src="https://pic3.zhimg.com/80/v2-45b52f39af117e90652db6c187bcde9e_720w.jpg" alt="img"></p>
<p>  我们设置name的过期时间为60秒，60秒内执行该set命令时，会直接返回nil。60秒后，我们再执行set命令，可以执行成功，效果如下：</p>
<p>  <img src="https://pic1.zhimg.com/80/v2-f3c9b8ceba26d0acd33de137b1398164_720w.jpg" alt="img"></p>
<p>  基于这个特性，升级后的分布式锁流程如下：</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-aced1e2ca7c8f8b4816089decbae0239_720w.jpg" alt="img"></p>
<p>  这种方式虽然解决了一些问题，但却引来了另外一个问题：存在锁误删的情况，也就是把别人加的锁释放了。例如，client1获得锁之后开始执行业务处理，但业务处理耗时较长，超过了锁的过期时间，导致业务处理还没结束时，锁却过期自动删除了（相当于属于client1的锁被释放了），此时，client2就会获取到这把锁，然后执行自己的业务处理，也就在此时，client1的业务处理结束了，然后向Redis发送了delete key的命令来释放锁，Redis接收到命令后，就直接将key删掉了，但此时这个key是属于client2的，所以，相当于client1把client2的锁给释放掉了：</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-9c3c50283915b97e762f021c3aed46d5_720w.jpg" alt="img"></p>
<p>  <strong>● 二次升级版本：value使用唯一值，删除锁时判断value是否当前线程的</strong></p>
<p>  要解决上面的问题，最省事的做法就是把锁的过期时间设置长一点，要远大于业务处理时间，但这样就会严重影响系统的性能，假如一台服务器在释放锁之前宕机了，而锁的超时时间设置了一个小时，那么在这一个小时内，其他线程访问这个服务时就一直阻塞在那里。所以，一般不推荐使用这种方式。</p>
<p>  另一种解决方法就是在set key value ex seconds nx时，把value设置成一个唯一值，每个线程的value都不一样，在删除key之前，先通过get key命令得到value，然后判断value是否是自己线程生成的，如果是，则删除掉key释放锁，如果不是，则不删除key。正常流程如下：</p>
<p>  <img src="https://pic3.zhimg.com/80/v2-59a27f7eb657f80d9f55a7827cda4c66_720w.jpg" alt="img"></p>
<p>  当业务处理还没结束的时候，key自动过期了，也可以正常释放自己的锁，不影响其他线程：</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-fe7780174d3bcd8ddb4403d234aa1071_720w.jpg" alt="img"></p>
<p>  二次升级后的方案看起来似乎已经没什么问题了，但其实不然。仔细分析流程后我们发现，判断锁是否属于当前线程和释放锁两个步骤并不是原子操作。正常来说，如果线程1通过get操作从Redis中得到的value是123，那么就会执行删除锁的操作，但假如在执行删除锁的动作之前，系统卡顿了几秒钟，恰好在这几秒钟内，key自动过期了，线程2就顺利获取到锁开始执行自己的逻辑了，此时，线程1卡顿恢复了，开始继续执行删除锁的动作，那么此时删除的还是线程2的锁。</p>
<p>  <img src="https://pic3.zhimg.com/80/v2-7e474b64ced92b1d8e42b003eae630fe_720w.jpg" alt="img"></p>
<p>  <strong>● 终极版本：Lua脚本</strong></p>
<p>  针对上述Redis原始命令无法满足部分业务原子性操作的问题，Redis提供了Lua脚本的支持。Lua脚本是一种轻量小巧的脚本语言，它支持原子性操作，Redis会将整个Lua脚本作为一个整体执行，中间不会被其他请求插入，因此Redis执行Lua脚本是一个原子操作。</p>
<p>  在上面的流程中，我们把get key value、判断value是否属于当前线程、删除锁这三步写到Lua脚本中，使它们变成一个整体交个Redis执行，改造后流程如下：</p>
<p>  <img src="https://pic1.zhimg.com/80/v2-a94366fc39908ca77943912b793162fc_720w.jpg" alt="img"></p>
<p>  这样改造之后，就解决了释放锁时取值、判断值、删除锁等多个步骤无法保证原子操作的问题了。关于Lua脚本的语法可以自行学习，并不复杂，很简单，这里就不做过多讲述。</p>
<p>  既然Lua脚本可以在释放锁时使用，那肯定也能在加锁时使用，而且一般情况下，推荐使用Lua脚本，因为在使用上面set key value ex seconds nx命令加锁时，并不能做到重入锁的效果，也就是当一个线程获取到锁后，在没有释放这把锁之前，当前线程自己也无法再获得这把锁，这显然会影响系统的性能。使用Lua脚本就可以解决这个问题，我们可以在Lua脚本中先判断锁（key）是否存在，如果存在则再判断持有这把锁的线程是否是当前线程，如果不是则加锁失败，否则当前线程再次持有这把锁，并把锁的重入次数+1。在释放锁时，也是先判断持有锁的线程是否是当前线程，如果是则将锁的重入次数-1，直至重入次数减至0，即可删除该锁（key）。</p>
<p>  <img src="https://pic2.zhimg.com/80/v2-bf27fd90f653b999345b6d05c2447c2d_720w.jpg" alt="img"></p>
<p>  实际项目开发中，其实基本不用自己写上面这些分布式锁的实现逻辑，而是使用一些很成熟的第三方工具，当下比较流行的就是Redisson，它既提供了Redis的基本命令的封装，也提供了Redis分布式锁的封装，使用非常简单，只需直接调用相应方法即可。但工具虽然好用，底层原理还是要理解的，这就是本篇文章的目的。</p>
<hr>
<h1 id="-">参考文献</h1>
<p>[1] <a href="https://www.52doc.com/detail/617">Redis开发与运维</a></p>
<p>[2] <a href="https://zh.wikipedia.org/zh/Raft">Raft维基百科</a></p>

          	</article>
        </div>
		</div>
  </body>
</html>
<script type="text/javascript" src="toc/js/jquery-1.4.4.min.js"></script>
<script type="text/javascript" src="toc/js/jquery.ztree.all-3.5.min.js"></script>
<script type="text/javascript" src="toc/js/ztree_toc.js"></script>
<script type="text/javascript" src="toc_conf.js"></script>

<SCRIPT type="text/javascript" >
<!--
$(document).ready(function(){
    var css_conf = eval(markdown_panel_style);
    $('#readme').css(css_conf)
    
    var conf = eval(jquery_ztree_toc_opts);
		$('#tree').ztree_toc(conf);
});
//-->
</SCRIPT>